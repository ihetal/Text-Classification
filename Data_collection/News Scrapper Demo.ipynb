{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import newspaper\n",
    "from newspaper import news_pool\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting default working directory\n",
    "os.chdir('C:/Users/Hetal/Desktop/SJSU/CMPE - 255/Project/bbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of news papers to crawl and the categories to look for\n",
    "\n",
    "papers_dict = {   \n",
    "    'BBC': {\n",
    "        'URL':'http://www.bbc.com',\n",
    "    },\n",
    "    'BBC_UK': {\n",
    "        'URL':'http://www.bbc.co.uk',\n",
    "    },\n",
    "    'SLATE': {\n",
    "        'URL':'http://www.slate.com',\n",
    "    },\n",
    "    'GUARDIAN': {\n",
    "        'URL':'http://www.theguardian.com',\n",
    "    },\n",
    "    'BREITBRAT': {\n",
    "        'URL':'http://www.breitbart.com',\n",
    "    },\n",
    "    'NBC': {\n",
    "        'URL':'http://www.nbcnews.com',\n",
    "    },\n",
    "    'WASHINGTONPOST': {\n",
    "        'URL':'http://www.washingtonpost.com',\n",
    "    },\n",
    "    'USNEWS': {\n",
    "        'URL':'http://www.usnews.com/', \n",
    "    },\n",
    "    'NYTIMES': {\n",
    "        'URL':'http://www.nytimes.com/', \n",
    "    },\n",
    "    'USATODAY': {\n",
    "        'URL':'http://www.usatoday.com/', \n",
    "    },\n",
    "    'NYDAILYNEWS': {\n",
    "        'URL':'http://www.nydailynews.com', \n",
    "    },\n",
    "    'LATIMES': {\n",
    "        'URL':'http://www.latimes.com/', \n",
    "    },\n",
    "    'WALLSTREETJOURNAL': {\n",
    "        'URL':'http://www.wsj.com/', \n",
    "    },\n",
    "    'BUSINESS_STANDARD': {\n",
    "        'URL':'http://www.business-standard.com/', \n",
    "    },\n",
    "    'LIVEMINT': {\n",
    "        'URL':'http://www.livemint.com', \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadContent(paper):\n",
    "\n",
    "    patterns = ['/politics/','/tech/','/technology/','/business/','/entertainment/','/health/']\n",
    "    type = []\n",
    "    news = []\n",
    "    url =  []\n",
    "    count = 0\n",
    "    for article in paper.articles:\n",
    "        try:\n",
    "            for pattern in patterns:\n",
    "                if(re.search(pattern,article.url)):\n",
    "                    if article.url not in url:\n",
    "                        article.download()\n",
    "                        article.parse()\n",
    "                        if(len(article.text) > 350 and len(article.text)<6000):\n",
    "                            news.append(article.text)\n",
    "                            type.append(pattern[1:-1])\n",
    "                            count = count + 1\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    print(\"No of articles crawled : \", count);\n",
    "    combined_data = {'category': type, 'news': news}\n",
    "    dataset = pd.DataFrame(combined_data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling from:  http://www.bbc.com\n",
      "No of articles crawled :  4\n",
      "Crawling from:  http://www.bbc.co.uk\n",
      "No of articles crawled :  0\n",
      "Crawling from:  http://www.slate.com\n",
      "No of articles crawled :  9\n",
      "Crawling from:  http://www.theguardian.com\n",
      "No of articles crawled :  6\n",
      "Crawling from:  http://www.breitbart.com\n",
      "No of articles crawled :  258\n",
      "Crawling from:  http://www.nbcnews.com\n",
      "No of articles crawled :  0\n",
      "Crawling from:  http://www.washingtonpost.com\n",
      "No of articles crawled :  16\n",
      "Crawling from:  http://www.usnews.com/\n",
      "No of articles crawled :  10\n",
      "Crawling from:  http://www.nytimes.com/\n",
      "No of articles crawled :  28\n",
      "Crawling from:  http://www.usatoday.com/\n",
      "No of articles crawled :  48\n",
      "Crawling from:  http://www.nydailynews.com\n",
      "No of articles crawled :  23\n",
      "Crawling from:  http://www.latimes.com/\n",
      "No of articles crawled :  12\n",
      "Crawling from:  http://www.wsj.com/\n",
      "No of articles crawled :  1\n",
      "Crawling from:  http://www.business-standard.com/\n",
      "No of articles crawled :  42\n",
      "Crawling from:  http://www.livemint.com\n",
      "No of articles crawled :  46\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "for name,value in papers_dict.items():\n",
    "    print(\"Crawling from: \", value['URL'])\n",
    "    paper = newspaper.build(value['URL'], language = 'en')\n",
    "    df = downloadContent(paper)\n",
    "    result = pd.concat([df, result], ignore_index=True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "politics         91\n",
       "sports           66\n",
       "technology       29\n",
       "entertainment    28\n",
       "world            20\n",
       "business         16\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping ALL duplicte values \n",
    "result.drop_duplicates(subset =\"news\", \n",
    "                     keep = \"first\", inplace = True)\n",
    "result.loc[(result.category == 'tech'),'category']='technology'\n",
    "result.loc[(result.category == 'sport'),'category']='sports'\n",
    "result['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset.csv', 'a+', encoding=\"utf-8-sig\", newline='') as f:\n",
    "    result.to_csv(f, header=False, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
